{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tugas Kecil II IF3170 Inteligensi Buatan\n",
    "# Eksplorasi scikit-learn pada Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implemented by:\n",
    "# Stevanno Hero Leadervand (13515082)\n",
    "# Gianfranco Fertino Hwandiano (13515118)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "5                  5.4               3.9                1.7               0.4   \n",
      "6                  4.6               3.4                1.4               0.3   \n",
      "7                  5.0               3.4                1.5               0.2   \n",
      "8                  4.4               2.9                1.4               0.2   \n",
      "9                  4.9               3.1                1.5               0.1   \n",
      "10                 5.4               3.7                1.5               0.2   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "12                 4.8               3.0                1.4               0.1   \n",
      "13                 4.3               3.0                1.1               0.1   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "16                 5.4               3.9                1.3               0.4   \n",
      "17                 5.1               3.5                1.4               0.3   \n",
      "18                 5.7               3.8                1.7               0.3   \n",
      "19                 5.1               3.8                1.5               0.3   \n",
      "20                 5.4               3.4                1.7               0.2   \n",
      "21                 5.1               3.7                1.5               0.4   \n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "23                 5.1               3.3                1.7               0.5   \n",
      "24                 4.8               3.4                1.9               0.2   \n",
      "25                 5.0               3.0                1.6               0.2   \n",
      "26                 5.0               3.4                1.6               0.4   \n",
      "27                 5.2               3.5                1.5               0.2   \n",
      "28                 5.2               3.4                1.4               0.2   \n",
      "29                 4.7               3.2                1.6               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "120                6.9               3.2                5.7               2.3   \n",
      "121                5.6               2.8                4.9               2.0   \n",
      "122                7.7               2.8                6.7               2.0   \n",
      "123                6.3               2.7                4.9               1.8   \n",
      "124                6.7               3.3                5.7               2.1   \n",
      "125                7.2               3.2                6.0               1.8   \n",
      "126                6.2               2.8                4.8               1.8   \n",
      "127                6.1               3.0                4.9               1.8   \n",
      "128                6.4               2.8                5.6               2.1   \n",
      "129                7.2               3.0                5.8               1.6   \n",
      "130                7.4               2.8                6.1               1.9   \n",
      "131                7.9               3.8                6.4               2.0   \n",
      "132                6.4               2.8                5.6               2.2   \n",
      "133                6.3               2.8                5.1               1.5   \n",
      "134                6.1               2.6                5.6               1.4   \n",
      "135                7.7               3.0                6.1               2.3   \n",
      "136                6.3               3.4                5.6               2.4   \n",
      "137                6.4               3.1                5.5               1.8   \n",
      "138                6.0               3.0                4.8               1.8   \n",
      "139                6.9               3.1                5.4               2.1   \n",
      "140                6.7               3.1                5.6               2.4   \n",
      "141                6.9               3.1                5.1               2.3   \n",
      "142                5.8               2.7                5.1               1.9   \n",
      "143                6.8               3.2                5.9               2.3   \n",
      "144                6.7               3.3                5.7               2.5   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "5       0.0  \n",
      "6       0.0  \n",
      "7       0.0  \n",
      "8       0.0  \n",
      "9       0.0  \n",
      "10      0.0  \n",
      "11      0.0  \n",
      "12      0.0  \n",
      "13      0.0  \n",
      "14      0.0  \n",
      "15      0.0  \n",
      "16      0.0  \n",
      "17      0.0  \n",
      "18      0.0  \n",
      "19      0.0  \n",
      "20      0.0  \n",
      "21      0.0  \n",
      "22      0.0  \n",
      "23      0.0  \n",
      "24      0.0  \n",
      "25      0.0  \n",
      "26      0.0  \n",
      "27      0.0  \n",
      "28      0.0  \n",
      "29      0.0  \n",
      "..      ...  \n",
      "120     2.0  \n",
      "121     2.0  \n",
      "122     2.0  \n",
      "123     2.0  \n",
      "124     2.0  \n",
      "125     2.0  \n",
      "126     2.0  \n",
      "127     2.0  \n",
      "128     2.0  \n",
      "129     2.0  \n",
      "130     2.0  \n",
      "131     2.0  \n",
      "132     2.0  \n",
      "133     2.0  \n",
      "134     2.0  \n",
      "135     2.0  \n",
      "136     2.0  \n",
      "137     2.0  \n",
      "138     2.0  \n",
      "139     2.0  \n",
      "140     2.0  \n",
      "141     2.0  \n",
      "142     2.0  \n",
      "143     2.0  \n",
      "144     2.0  \n",
      "145     2.0  \n",
      "146     2.0  \n",
      "147     2.0  \n",
      "148     2.0  \n",
      "149     2.0  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = datasets.load_iris()\n",
    "content = data.data\n",
    "target  = data.target\n",
    "\n",
    "# Display dataset\n",
    "print(pd.DataFrame(data = np.c_[content, target], columns = data.feature_names + ['target']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading 'play tennis' dataset  from .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     outlook temperature humidity   wind playtennis\n",
      "0      sunny         hot     high  False         no\n",
      "1      sunny         hot     high   True         no\n",
      "2   overcast         hot     high  False        yes\n",
      "3       rain        mild     high  False        yes\n",
      "4       rain        cool   normal  False        yes\n",
      "5       rain        cool   normal   True         no\n",
      "6   overcast        cool   normal   True        yes\n",
      "7      sunny        mild     high  False         no\n",
      "8      sunny        cool   normal  False        yes\n",
      "9       rain        mild   normal  False        yes\n",
      "10     sunny        mild   normal   True        yes\n",
      "11  overcast        mild     high   True        yes\n",
      "12  overcast         hot   normal  False        yes\n",
      "13      rain        mild     high   True         no\n"
     ]
    }
   ],
   "source": [
    "tennis = pd.read_csv(\"play-tennis.csv\")\n",
    "print(tennis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning iris dataset with full training \n",
    "## NaïveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of each class: \n",
      "['setosa' 'versicolor' 'virginica']\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      "\n",
      "Means of attribute of every class: \n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0              5.006             3.418              1.464             0.244\n",
      "1              5.936             2.770              4.260             1.326\n",
      "2              6.588             2.974              5.552             2.026\n",
      "\n",
      "Variance of attribute of every class: \n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.121764          0.142276           0.029504          0.011264\n",
      "1           0.261104          0.096500           0.216400          0.038324\n",
      "2           0.396256          0.101924           0.298496          0.073924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "GNBlearn = gnb.fit(content, target)\n",
    "\n",
    "prob_class = gnb.class_prior_\n",
    "print(\"Probability of each class: \")\n",
    "print(data.target_names)\n",
    "print(prob_class)\n",
    "\n",
    "print()\n",
    "\n",
    "feature_mean = gnb.theta_\n",
    "print(\"Means of attribute of every class: \")\n",
    "print(pd.DataFrame(data = np.c_[feature_mean], columns = data.feature_names))\n",
    "\n",
    "print()\n",
    "\n",
    "feature_variance = gnb.sigma_\n",
    "print(\"Variance of attribute of every class: \")\n",
    "print(pd.DataFrame(data = np.c_[feature_variance], columns = data.feature_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"892pt\" height=\"671pt\"\r\n",
       " viewBox=\"0.00 0.00 892.00 671.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 667)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-667 888,-667 888,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M536,-663C536,-663 395,-663 395,-663 389,-663 383,-657 383,-651 383,-651 383,-592 383,-592 383,-586 389,-580 395,-580 395,-580 536,-580 536,-580 542,-580 548,-586 548,-592 548,-592 548,-651 548,-651 548,-657 542,-663 536,-663\"/>\r\n",
       "<text text-anchor=\"start\" x=\"391\" y=\"-647.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 2.45</text>\r\n",
       "<text text-anchor=\"start\" x=\"415.5\" y=\"-632.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.585</text>\r\n",
       "<text text-anchor=\"start\" x=\"418\" y=\"-617.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 150</text>\r\n",
       "<text text-anchor=\"start\" x=\"405\" y=\"-602.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 50, 50]</text>\r\n",
       "<text text-anchor=\"start\" x=\"419.5\" y=\"-587.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M435,-536.5C435,-536.5 338,-536.5 338,-536.5 332,-536.5 326,-530.5 326,-524.5 326,-524.5 326,-480.5 326,-480.5 326,-474.5 332,-468.5 338,-468.5 338,-468.5 435,-468.5 435,-468.5 441,-468.5 447,-474.5 447,-480.5 447,-480.5 447,-524.5 447,-524.5 447,-530.5 441,-536.5 435,-536.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"344.5\" y=\"-521.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"343\" y=\"-506.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\r\n",
       "<text text-anchor=\"start\" x=\"334\" y=\"-491.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 0, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"340.5\" y=\"-476.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M438.091,-579.907C430.492,-568.652 422.231,-556.418 414.593,-545.106\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417.391,-542.996 408.895,-536.667 411.59,-546.913 417.391,-542.996\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"404.136\" y=\"-557.51\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M612,-544C612,-544 477,-544 477,-544 471,-544 465,-538 465,-532 465,-532 465,-473 465,-473 465,-467 471,-461 477,-461 477,-461 612,-461 612,-461 618,-461 624,-467 624,-473 624,-473 624,-532 624,-532 624,-538 618,-544 612,-544\"/>\r\n",
       "<text text-anchor=\"start\" x=\"473\" y=\"-528.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.75</text>\r\n",
       "<text text-anchor=\"start\" x=\"502.5\" y=\"-513.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 1.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"497\" y=\"-498.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100</text>\r\n",
       "<text text-anchor=\"start\" x=\"488\" y=\"-483.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 50, 50]</text>\r\n",
       "<text text-anchor=\"start\" x=\"489\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>0&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M492.909,-579.907C498.914,-571.014 505.331,-561.509 511.529,-552.331\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"514.444,-554.267 517.14,-544.021 508.643,-550.35 514.444,-554.267\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"521.898\" y=\"-564.864\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.898039\" stroke=\"black\" d=\"M500,-425C500,-425 359,-425 359,-425 353,-425 347,-419 347,-413 347,-413 347,-354 347,-354 347,-348 353,-342 359,-342 359,-342 500,-342 500,-342 506,-342 512,-348 512,-354 512,-354 512,-413 512,-413 512,-419 506,-425 500,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"355\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"379.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.445</text>\r\n",
       "<text text-anchor=\"start\" x=\"386\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 54</text>\r\n",
       "<text text-anchor=\"start\" x=\"377\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 49, 5]</text>\r\n",
       "<text text-anchor=\"start\" x=\"374\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M504.601,-460.907C495.503,-451.651 485.754,-441.732 476.393,-432.209\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.834,-429.699 469.328,-425.021 473.842,-434.606 478.834,-429.699\"/>\r\n",
       "</g>\r\n",
       "<!-- 12 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>12</title>\r\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.976471\" stroke=\"black\" d=\"M731,-425C731,-425 590,-425 590,-425 584,-425 578,-419 578,-413 578,-413 578,-354 578,-354 578,-348 584,-342 590,-342 590,-342 731,-342 731,-342 737,-342 743,-348 743,-354 743,-354 743,-413 743,-413 743,-419 737,-425 731,-425\"/>\r\n",
       "<text text-anchor=\"start\" x=\"586\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 4.85</text>\r\n",
       "<text text-anchor=\"start\" x=\"610.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.151</text>\r\n",
       "<text text-anchor=\"start\" x=\"617\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 46</text>\r\n",
       "<text text-anchor=\"start\" x=\"608\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 45]</text>\r\n",
       "<text text-anchor=\"start\" x=\"610.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;12 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>2&#45;&gt;12</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M584.746,-460.907C593.923,-451.651 603.757,-441.732 613.199,-432.209\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"615.77,-434.586 620.326,-425.021 610.799,-429.658 615.77,-434.586\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.980392\" stroke=\"black\" d=\"M271,-306C271,-306 136,-306 136,-306 130,-306 124,-300 124,-294 124,-294 124,-235 124,-235 124,-229 130,-223 136,-223 136,-223 271,-223 271,-223 277,-223 283,-229 283,-235 283,-235 283,-294 283,-294 283,-300 277,-306 271,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"132\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.65</text>\r\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.146</text>\r\n",
       "<text text-anchor=\"start\" x=\"160\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\r\n",
       "<text text-anchor=\"start\" x=\"151\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.09,-341.907C331.632,-331.834 310.66,-320.977 290.805,-310.698\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.261,-307.51 281.771,-306.021 289.042,-313.726 292.261,-307.51\"/>\r\n",
       "</g>\r\n",
       "<!-- 7 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>7</title>\r\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M497,-306C497,-306 362,-306 362,-306 356,-306 350,-300 350,-294 350,-294 350,-235 350,-235 350,-229 356,-223 362,-223 362,-223 497,-223 497,-223 503,-223 509,-229 509,-235 509,-235 509,-294 509,-294 509,-300 503,-306 497,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"358\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) ≤ 1.55</text>\r\n",
       "<text text-anchor=\"start\" x=\"379.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\r\n",
       "<text text-anchor=\"start\" x=\"390\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"381\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 4]</text>\r\n",
       "<text text-anchor=\"start\" x=\"379.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;7 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>3&#45;&gt;7</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.5,-341.907C429.5,-333.649 429.5,-324.864 429.5,-316.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"433,-316.021 429.5,-306.021 426,-316.021 433,-316.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 5 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M115,-179.5C115,-179.5 12,-179.5 12,-179.5 6,-179.5 -7.10543e-015,-173.5 -7.10543e-015,-167.5 -7.10543e-015,-167.5 -7.10543e-015,-123.5 -7.10543e-015,-123.5 -7.10543e-015,-117.5 6,-111.5 12,-111.5 12,-111.5 115,-111.5 115,-111.5 121,-111.5 127,-117.5 127,-123.5 127,-123.5 127,-167.5 127,-167.5 127,-173.5 121,-179.5 115,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"20\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\r\n",
       "<text text-anchor=\"start\" x=\"11\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 47, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;5 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>4&#45;&gt;5</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.928,-222.907C140.668,-210.99 125.095,-197.976 110.908,-186.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.105,-183.394 103.187,-179.667 108.616,-188.765 113.105,-183.394\"/>\r\n",
       "</g>\r\n",
       "<!-- 6 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M249.5,-179.5C249.5,-179.5 157.5,-179.5 157.5,-179.5 151.5,-179.5 145.5,-173.5 145.5,-167.5 145.5,-167.5 145.5,-123.5 145.5,-123.5 145.5,-117.5 151.5,-111.5 157.5,-111.5 157.5,-111.5 249.5,-111.5 249.5,-111.5 255.5,-111.5 261.5,-117.5 261.5,-123.5 261.5,-123.5 261.5,-167.5 261.5,-167.5 261.5,-173.5 255.5,-179.5 249.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"164\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"155\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 4&#45;&gt;6 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>4&#45;&gt;6</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M203.5,-222.907C203.5,-212.204 203.5,-200.615 203.5,-189.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207,-189.667 203.5,-179.667 200,-189.667 207,-189.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 8 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>8</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M383.5,-179.5C383.5,-179.5 291.5,-179.5 291.5,-179.5 285.5,-179.5 279.5,-173.5 279.5,-167.5 279.5,-167.5 279.5,-123.5 279.5,-123.5 279.5,-117.5 285.5,-111.5 291.5,-111.5 291.5,-111.5 383.5,-111.5 383.5,-111.5 389.5,-111.5 395.5,-117.5 395.5,-123.5 395.5,-123.5 395.5,-167.5 395.5,-167.5 395.5,-173.5 389.5,-179.5 383.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"295.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"298\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"289\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"287.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;8 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>7&#45;&gt;8</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M397.581,-222.907C388.644,-211.542 378.922,-199.178 369.955,-187.774\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"372.513,-185.364 363.58,-179.667 367.01,-189.691 372.513,-185.364\"/>\r\n",
       "</g>\r\n",
       "<!-- 9 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>9</title>\r\n",
       "<path fill=\"#39e581\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M567,-187C567,-187 426,-187 426,-187 420,-187 414,-181 414,-175 414,-175 414,-116 414,-116 414,-110 420,-104 426,-104 426,-104 567,-104 567,-104 573,-104 579,-110 579,-116 579,-116 579,-175 579,-175 579,-181 573,-187 567,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"422\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) ≤ 5.45</text>\r\n",
       "<text text-anchor=\"start\" x=\"446.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\r\n",
       "<text text-anchor=\"start\" x=\"457\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"448\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"441\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 7&#45;&gt;9 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>7&#45;&gt;9</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M452.745,-222.907C457.734,-214.195 463.059,-204.897 468.215,-195.893\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"471.364,-197.438 473.296,-187.021 465.289,-193.959 471.364,-197.438\"/>\r\n",
       "</g>\r\n",
       "<!-- 10 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>10</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M478,-68C478,-68 375,-68 375,-68 369,-68 363,-62 363,-56 363,-56 363,-12 363,-12 363,-6 369,-0 375,-0 375,-0 478,-0 478,-0 484,-0 490,-6 490,-12 490,-12 490,-56 490,-56 490,-62 484,-68 478,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"384.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"387\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"378\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"371\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;10 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>9&#45;&gt;10</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M470.435,-103.726C464.837,-94.9703 458.913,-85.7032 453.289,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"456.123,-74.8399 447.787,-68.2996 450.225,-78.6103 456.123,-74.8399\"/>\r\n",
       "</g>\r\n",
       "<!-- 11 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>11</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M612.5,-68C612.5,-68 520.5,-68 520.5,-68 514.5,-68 508.5,-62 508.5,-56 508.5,-56 508.5,-12 508.5,-12 508.5,-6 514.5,-0 520.5,-0 520.5,-0 612.5,-0 612.5,-0 618.5,-0 624.5,-6 624.5,-12 624.5,-12 624.5,-56 624.5,-56 624.5,-62 618.5,-68 612.5,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"524.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"527\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"518\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\r\n",
       "<text text-anchor=\"start\" x=\"516.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 9&#45;&gt;11 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>9&#45;&gt;11</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M522.565,-103.726C528.163,-94.9703 534.087,-85.7032 539.711,-76.9051\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"542.775,-78.6103 545.213,-68.2996 536.877,-74.8399 542.775,-78.6103\"/>\r\n",
       "</g>\r\n",
       "<!-- 13 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>13</title>\r\n",
       "<path fill=\"#8139e5\" fill-opacity=\"0.498039\" stroke=\"black\" d=\"M733,-306C733,-306 588,-306 588,-306 582,-306 576,-300 576,-294 576,-294 576,-235 576,-235 576,-229 582,-223 588,-223 588,-223 733,-223 733,-223 739,-223 745,-229 745,-235 745,-235 745,-294 745,-294 745,-300 739,-306 733,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"584\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sepal length (cm) ≤ 5.95</text>\r\n",
       "<text text-anchor=\"start\" x=\"610.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.918</text>\r\n",
       "<text text-anchor=\"start\" x=\"621\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"612\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"610.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;13 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>12&#45;&gt;13</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M660.5,-341.907C660.5,-333.649 660.5,-324.864 660.5,-316.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"664,-316.021 660.5,-306.021 657,-316.021 664,-316.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 16 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>16</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M872,-298.5C872,-298.5 775,-298.5 775,-298.5 769,-298.5 763,-292.5 763,-286.5 763,-286.5 763,-242.5 763,-242.5 763,-236.5 769,-230.5 775,-230.5 775,-230.5 872,-230.5 872,-230.5 878,-230.5 884,-236.5 884,-242.5 884,-242.5 884,-286.5 884,-286.5 884,-292.5 878,-298.5 872,-298.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"781.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"780\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\r\n",
       "<text text-anchor=\"start\" x=\"771\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 43]</text>\r\n",
       "<text text-anchor=\"start\" x=\"773.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 12&#45;&gt;16 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>12&#45;&gt;16</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M717.052,-341.907C733.808,-329.88 752.122,-316.735 768.761,-304.791\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"771.21,-307.342 777.293,-298.667 767.128,-301.655 771.21,-307.342\"/>\r\n",
       "</g>\r\n",
       "<!-- 14 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>14</title>\r\n",
       "<path fill=\"#39e581\" stroke=\"black\" d=\"M712,-179.5C712,-179.5 609,-179.5 609,-179.5 603,-179.5 597,-173.5 597,-167.5 597,-167.5 597,-123.5 597,-123.5 597,-117.5 603,-111.5 609,-111.5 609,-111.5 712,-111.5 712,-111.5 718,-111.5 724,-117.5 724,-123.5 724,-123.5 724,-167.5 724,-167.5 724,-173.5 718,-179.5 712,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"618.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"621\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\r\n",
       "<text text-anchor=\"start\" x=\"612\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"605\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;14 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>13&#45;&gt;14</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M660.5,-222.907C660.5,-212.204 660.5,-200.615 660.5,-189.776\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"664,-189.667 660.5,-179.667 657,-189.667 664,-189.667\"/>\r\n",
       "</g>\r\n",
       "<!-- 15 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>15</title>\r\n",
       "<path fill=\"#8139e5\" stroke=\"black\" d=\"M846.5,-179.5C846.5,-179.5 754.5,-179.5 754.5,-179.5 748.5,-179.5 742.5,-173.5 742.5,-167.5 742.5,-167.5 742.5,-123.5 742.5,-123.5 742.5,-117.5 748.5,-111.5 754.5,-111.5 754.5,-111.5 846.5,-111.5 846.5,-111.5 852.5,-111.5 858.5,-117.5 858.5,-123.5 858.5,-123.5 858.5,-167.5 858.5,-167.5 858.5,-173.5 852.5,-179.5 846.5,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"758.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"761\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\r\n",
       "<text text-anchor=\"start\" x=\"752\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 2]</text>\r\n",
       "<text text-anchor=\"start\" x=\"750.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\r\n",
       "</g>\r\n",
       "<!-- 13&#45;&gt;15 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>13&#45;&gt;15</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M709.072,-222.907C723.332,-210.99 738.905,-197.976 753.092,-186.12\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"755.384,-188.765 760.813,-179.667 750.895,-183.394 755.384,-188.765\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x24e4c5421d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "ID3learn = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "ID3learn.fit(content, target)\n",
    "\n",
    "dot_data = tree.export_graphviz(ID3learn, out_file=None, \n",
    "                         feature_names=data.feature_names,  \n",
    "                         class_names=data.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqFDKPSKiQin3iIgKpdwjIir0D+yOFB8odQ8dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24e4acffdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 15\n",
    "\n",
    "# Take only the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = content[:, :2]\n",
    "y = target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# Create an instance of Neighbours Classifier and fit the data.\n",
    "KNNlearn = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "KNNlearn.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = KNNlearn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "            edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "          % (n_neighbors, 'uniform'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Matrices: \n",
      "[array([[-0.24128898,  0.56486019, -0.223678  ,  0.46123528,  0.12169184],\n",
      "       [-0.29050288, -0.15024022, -0.24648664, -0.50147971, -0.25901612],\n",
      "       [ 0.41417217, -0.0056925 ,  0.08247478, -0.17169154, -0.44347906],\n",
      "       [-0.56488487, -0.53648203,  0.40282769, -0.13760786,  0.74074944]]), array([[ 0.35431404,  0.66049394],\n",
      "       [-0.83737802, -0.23168898],\n",
      "       [ 0.47111071,  0.46477351],\n",
      "       [ 0.85854096,  0.04219051],\n",
      "       [-0.77183571,  0.21051908]]), array([[ 0.20846906,  0.08453928, -0.27518014],\n",
      "       [ 0.01301847,  0.07112233, -0.08999098]])]\n",
      "\n",
      "Bias Vectors: \n",
      "[array([ 0.65233727, -0.42304612,  0.24281928, -0.50674168,  0.07812664]), array([ 0.40569153, -0.61226737]), array([ 0.79916012,  0.79914202,  0.79914076])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MLPlearn = MLPClassifier(solver='lbfgs',\n",
    "                hidden_layer_sizes=(5, 2))\n",
    "MLPlearn.fit(content, target)\n",
    "\n",
    "# Element[i,j] represents the weight of element-j on layer i\n",
    "print(\"Weight Matrices: \")\n",
    "print(MLPlearn.coefs_)\n",
    "print()\n",
    "\n",
    "# Element[i,j] represents the bias for element-j on layer i\n",
    "print(\"Bias Vectors: \")\n",
    "print(MLPlearn.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning iris dataset with split : train 90% & test 10% schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(content, target, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaïveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accuracy:  100.0%\n",
      "\n",
      "2. Precision: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "3. Recall: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "4. Confusion Matrix: \n",
      "[[6 0 0]\n",
      " [0 5 0]\n",
      " [0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "GNBlearn.fit(X_train, y_train)\n",
    "y_pred = GNBlearn.predict(X_test)\n",
    "\n",
    "print(\"1. Accuracy: \", str(metrics.accuracy_score(y_test,y_pred) * 100) + \"%\")\n",
    "print()\n",
    "\n",
    "precision = metrics.precision_score(y_test, y_pred, average=None) * 100\n",
    "print(\"2. Precision: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(precision[i]) + \"%\")\n",
    "print()\n",
    "    \n",
    "recall = metrics.recall_score(y_test, y_pred, average=None) * 100\n",
    "print(\"3. Recall: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(recall[i]) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"4. Confusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accuracy:  100.0%\n",
      "\n",
      "2. Precision: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "3. Recall: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "4. Confusion Matrix: \n",
      "[[6 0 0]\n",
      " [0 5 0]\n",
      " [0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "ID3learn.fit(X_train, y_train)\n",
    "y_pred = ID3learn.predict(X_test)\n",
    "\n",
    "print(\"1. Accuracy: \", str(metrics.accuracy_score(y_test,y_pred) * 100) + \"%\")\n",
    "print()\n",
    "\n",
    "precision = metrics.precision_score(y_test, y_pred, average=None) * 100\n",
    "print(\"2. Precision: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(precision[i]) + \"%\")\n",
    "print()\n",
    "    \n",
    "recall = metrics.recall_score(y_test, y_pred, average=None) * 100\n",
    "print(\"3. Recall: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(recall[i]) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"4. Confusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accuracy:  100.0%\n",
      "\n",
      "2. Precision: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "3. Recall: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "4. Confusion Matrix: \n",
      "[[6 0 0]\n",
      " [0 5 0]\n",
      " [0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "KNNlearn.fit(X_train, y_train)\n",
    "y_pred = KNNlearn.predict(X_test)\n",
    "\n",
    "print(\"1. Accuracy: \", str(metrics.accuracy_score(y_test,y_pred) * 100) + \"%\")\n",
    "print()\n",
    "\n",
    "precision = metrics.precision_score(y_test, y_pred, average=None) * 100\n",
    "print(\"2. Precision: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(precision[i]) + \"%\")\n",
    "print()\n",
    "    \n",
    "recall = metrics.recall_score(y_test, y_pred, average=None) * 100\n",
    "print(\"3. Recall: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(recall[i]) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"4. Confusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Accuracy:  100.0%\n",
      "\n",
      "2. Precision setiap kelas: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "3. Recall setiap kelas: \n",
      "setosa: 100.0%\n",
      "versicolor: 100.0%\n",
      "virginica: 100.0%\n",
      "\n",
      "4. Confusion Matrix: \n",
      "[[6 0 0]\n",
      " [0 5 0]\n",
      " [0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "MLPlearn.fit(X_train, y_train)\n",
    "y_pred = MLPlearn.predict(X_test)\n",
    "\n",
    "print(\"1. Accuracy: \", str(metrics.accuracy_score(y_test,y_pred) * 100) + \"%\")\n",
    "print()\n",
    "\n",
    "precision = metrics.precision_score(y_test, y_pred, average=None) * 100\n",
    "print(\"2. Precision setiap kelas: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(precision[i]) + \"%\")\n",
    "print()\n",
    "    \n",
    "recall = metrics.recall_score(y_test, y_pred, average=None) * 100\n",
    "print(\"3. Recall setiap kelas: \")\n",
    "for i in range(3):\n",
    "    print(data.target_names[i] + \": \" + str(recall[i]) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"4. Confusion Matrix: \")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning iris dataset with 10-fold cross validatation schema\n",
    "## NaïveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold-1: 0.93\n",
      "Fold-2: 0.93\n",
      "Fold-3: 1.00\n",
      "Fold-4: 0.93\n",
      "Fold-5: 0.93\n",
      "Fold-6: 0.93\n",
      "Fold-7: 0.87\n",
      "Fold-8: 1.00\n",
      "Fold-9: 1.00\n",
      "Fold-10: 1.00\n",
      "\n",
      "Mean: 0.95\n",
      "Accuration: 0.95 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(GNBlearn, content, target, cv=10)\n",
    "\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.2f\" % score[i])\n",
    "print()\n",
    "print(\"Mean: %0.2f\" % score.mean())\n",
    "print(\"Accuration: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold-1: 1.00\n",
      "Fold-2: 0.93\n",
      "Fold-3: 1.00\n",
      "Fold-4: 0.93\n",
      "Fold-5: 0.93\n",
      "Fold-6: 0.87\n",
      "Fold-7: 0.93\n",
      "Fold-8: 1.00\n",
      "Fold-9: 1.00\n",
      "Fold-10: 1.00\n",
      "\n",
      "Mean: 0.96\n",
      "Accuration: 0.96 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(ID3learn, content, target, cv=10)\n",
    "\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.2f\" % score[i])\n",
    "print()\n",
    "print(\"Mean: %0.2f\" % score.mean())\n",
    "print(\"Accuration: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold-1: 0.67\n",
      "Fold-2: 0.80\n",
      "Fold-3: 0.73\n",
      "Fold-4: 0.80\n",
      "Fold-5: 0.67\n",
      "Fold-6: 0.67\n",
      "Fold-7: 0.93\n",
      "Fold-8: 0.80\n",
      "Fold-9: 0.93\n",
      "Fold-10: 0.73\n",
      "\n",
      "Mean: 0.77\n",
      "Accuration: 0.77 (+/- 0.19)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(KNNlearn, X, y, cv=10)\n",
    "\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.2f\" % score[i])\n",
    "print()\n",
    "print(\"Mean: %0.2f\" % score.mean())\n",
    "print(\"Accuration: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold-1: 0.33\n",
      "Fold-2: 0.80\n",
      "Fold-3: 0.33\n",
      "Fold-4: 0.33\n",
      "Fold-5: 0.33\n",
      "Fold-6: 0.33\n",
      "Fold-7: 0.67\n",
      "Fold-8: 0.73\n",
      "Fold-9: 0.87\n",
      "Fold-10: 0.67\n",
      "\n",
      "Mean: 0.54\n",
      "Accuration: 0.54 (+/- 0.43)\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(MLPlearn, X, y, cv=10)\n",
    "\n",
    "print()\n",
    "for i in range(10):\n",
    "    print(\"Fold-\" + str(i + 1) + \":\", \"%0.2f\" % score[i])\n",
    "print()\n",
    "print(\"Mean: %0.2f\" % score.mean())\n",
    "print(\"Accuration: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving learning model/hypothesis into external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DT.model']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(KNNlearn, 'kNN.model')\n",
    "joblib.dump(MLPlearn, 'MLP.model')\n",
    "joblib.dump(GNBlearn, 'GNB.model')\n",
    "joblib.dump(ID3learn, 'DT.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading model/hypothesis from external file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNNlearn = joblib.load('kNN.model')\n",
    "MLPlearn = joblib.load('MLP.model')\n",
    "GNBlearn = joblib.load('GNB.model')\n",
    "ID3learn = joblib.load('DT.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making new instances by assigning value to each attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Instance: \n",
      "sepal length (cm): 3.0\n",
      "sepal width (cm): 3.1\n",
      "petal length (cm): 1.2\n",
      "petal width (cm): 0.3\n"
     ]
    }
   ],
   "source": [
    "newInstance = [3, 3.1, 1.2, 0.3]\n",
    "newInstance  = np.array([newInstance ])\n",
    "                \n",
    "print(\"New Instance: \")\n",
    "for i in range(4):\n",
    "    print(data.feature_names[i] + \":\", newInstance[0][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying new instances data using NaïveBayes, DecisionTree, kNN, and MLP model/hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaïveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names[GNBlearn.predict(newInstance)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names[ID3learn.predict(newInstance)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names[KNNlearn.predict(newInstance)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names[MLPlearn.predict(newInstance)][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
